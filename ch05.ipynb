{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5: Transformations and Weighting to Correct Model Inadequacies\n",
    "\n",
    "Recall that regression model fitting has several implicit assumptions, including the following:\n",
    "1. The model errors have mean zero and constant variance and are uncorrelated.\n",
    "2. The model errors have a normal distribution — this assumption is made in order to conduct hypothesis tests and construct CIs - —under this assumption, the errors are independent.\n",
    "3. The form of the model, including the specification of the regressors, is correct.\n",
    "\n",
    "In this chapter, we focus on methods and procedures for building regression models when some of the above assumptions are violated. We place considerable emphasis on data transformation. It is not unusual to find that when the response and/or the regressor variables are expressed in the correct scale of measurement or metric, certain violations of assumptions, such as inequality of variance, are no longer present.\n",
    "\n",
    "The method of weighted least squares is also useful in building regression models in situations where some of the underlying assumptions are violated. We will illus- trate how weighted least squares can be used when the equal-variance assumption is not appropriate.\n",
    "\n",
    "## 5.2 Variance-stabilizing transformations\n",
    "\n",
    "The assumption of constant variance is a basic requirement of regression analysis. A common reason for the violation of this assumption is for the response variable y to follow a probability distribution in which the variance is functionally related to the mean.\n",
    "\n",
    "Several commonly used variance-stabilizing transformations are summarized in Table 5.1. The strength of a transformation depends on the amount of curvature that it induces. The transformations given in Table 5.1 range from the relatively mild square root to the relatively strong reciprocal. Generally speaking, a mild transfor- mation applied over a relatively narrow range of values (e.g., ymax/ymin < 2, 3) has little effect. On the other hand, a strong transformation over a wide range of values will have a dramatic effect on the analysis.\n",
    "\n",
    "<img src=\"images/5_1.png\" height=\"250px\">\n",
    "\n",
    "It is important to detect and correct a nonconstant error variance. If this problem is not eliminated, the least-squares estimators will still be unbiased, but they will no longer have the minimum-variance property. This means that the regression coef- ficients will have larger standard errors than necessary. The effect of the transforma- tion is usually to give more precise estimates of the model parameters and increased sensitivity for the statistical tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Transormations to linearize the model\n",
    "\n",
    "The assumption of a linear relationship between y and the regressors is the usual starting point in regression analysis. Occasionally we find that this assumption is inappropriate. Nonlinearity may be detected via the lack-of-fit test described in Section 4.5 or from scatter diagrams, the matrix of scatterplots, or residual plots such as the partial regression plot. Sometimes prior experience or theoretical considerations may indicate that the relationship between $y$ and the regressors is not linear. In some cases a nonlinear function can be linearized by using a suitable transformation. Such nonlinear models are called intrinsically or transformably linear.\n",
    "\n",
    "Several linearizable functions are shown in Figure 5.4. The corresponding non- linear functions, transformations, and resulting linear forms are shown in Table 5.4. When the scatter diagram of y against x indicates curvature, we may be able to match the observed behavior of the plot to one of the curves in Figure 5.4 and use the linearized form of the function to represent the data.\n",
    "\n",
    "<img src=\"images/5_4.png\" height=\"250px\">\n",
    "<img src=\"images/5_4b.png\" height=\"250px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, consider the exponential function:\n",
    "\n",
    "$$y = b_0 e^{b_1x}\\epsilon$$\n",
    "\n",
    "This is intrinsically linear because it can be transformed to a straight line by a logarithmic transformation:\n",
    "\n",
    "$$\\ln y = \\ln b_0 + b_1x + \\ln \\epsilon.$$\n",
    "\n",
    "This transformation requires that the transformed error terms $\\epsilon' = \\ln \\epsilon$ are normally and independantly distributed with mean zero and variance $\\sigma_2$. This implies that the multiplicative error in the original model is log normally distributed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Analytical methods for selecting a transformation\n",
    "\n",
    "### 5.4.1 Transformations on $y$: The Box-Cox method\n",
    "\n",
    "Suppose we wish to transform $y$ to correct nonnormality and nonconstant variance. A useful class of transformations is the power transformation $y^\\lambda$, where $\\lambda$ is to be determined. \n",
    "\n",
    "Parameters of the regression, along with the $\\lambda$ can be estimated simultaneously using the method of maximum likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
